{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c83bdcbc",
      "metadata": {},
      "source": [
        "# SWE-bench Verified: SDLC Agent Evaluation\n",
        "\n",
        "This notebook runs the SDLC agent on SWE-bench Verified instances, writes a predictions JSONL file, and evaluates it with the SWE-bench harness.\n",
        "\n",
        "Notes:\n",
        "- You need Docker running to use the harness.\n",
        "- Generating patches requires API access for the SDLC agent model (see `.env` / env vars).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b34cec",
      "metadata": {},
      "source": [
        "## 1) Setup\n",
        "Install SWE-bench, datasets, and this project in your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0e812812",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'SWE-bench'...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Obtaining file:///D:/MegaScholaITMO/coding-agent/SWE-bench\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Checking if build backend supports build_editable: started\n",
            "  Checking if build backend supports build_editable: finished with status 'done'\n",
            "  Getting requirements to build editable: started\n",
            "  Getting requirements to build editable: finished with status 'done'\n",
            "  Preparing editable metadata (pyproject.toml): started\n",
            "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\zvrva\\appdata\\roaming\\python\\python312\\site-packages (from swebench==4.1.0) (4.14.3)\n",
            "INFO: pip is looking at multiple versions of swebench to determine which version is compatible with other requirements. This could take a while.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement chardet (from swebench) (from versions: none)\n",
            "ERROR: No matching distribution found for chardet\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/princeton-nlp/SWE-bench.git\n",
        "%pip install -e SWE-bench"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eac6527",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: install SWE-bench (recommended by SWE-bench docs)\n",
        "# !git clone https://github.com/princeton-nlp/SWE-bench.git\n",
        "# %pip install -e SWE-bench\n",
        "\n",
        "# Optional: install dependencies for this repo\n",
        "# %pip install -e .\n",
        "# %pip install datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c787c95",
      "metadata": {},
      "source": [
        "## 2) Config\n",
        "Update paths and knobs as needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fdc85e39",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "DATASET_NAME = \"princeton-nlp/SWE-bench_Verified\"\n",
        "SPLIT = \"test\"\n",
        "RUN_ID = \"sdlc-agent-verified\"\n",
        "MAX_WORKERS = 8\n",
        "MAX_INSTANCES = 5  # set to None for full run\n",
        "\n",
        "PREDICTIONS_PATH = Path(\"predictions.jsonl\")\n",
        "WORK_DIR = Path(\".swebench_work\")\n",
        "WORK_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "AGENT_NAME = \"sdlc-agent\"\n",
        "\n",
        "RETRY_MAX_ATTEMPTS = 8\n",
        "RETRY_BASE_DELAY_SEC = 10.0\n",
        "RETRY_MAX_DELAY_SEC = 60.0\n",
        "SLEEP_BETWEEN_INSTANCES_SEC = 7.0\n",
        "\n",
        "GIT_CLONE_TIMEOUT_SEC = 600.0\n",
        "GIT_CHECKOUT_TIMEOUT_SEC = 120.0\n",
        "DIFF_TIMEOUT_SEC = 60.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b4036a2",
      "metadata": {},
      "source": [
        "## 3) Load the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5f79327e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\zvrva\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Generating test split: 100%|██████████| 500/500 [00:00<00:00, 10177.09 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(DATASET_NAME, split=SPLIT)\n",
        "if MAX_INSTANCES is not None:\n",
        "    dataset = dataset.select(range(MAX_INSTANCES))\n",
        "len(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47d177fe",
      "metadata": {},
      "source": [
        "## 4) Agent runner (local patch generation)\n",
        "This uses the SDLC agent prompt and context builder to generate a patch per instance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0ffc579a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import subprocess\n",
        "import tempfile\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict\n",
        "\n",
        "from src.sdlc_agent.agent_code import PROMPT_CODE_PATCH, _apply_file_changes, _build_context\n",
        "from src.sdlc_agent.llm import chat, extract_json\n",
        "\n",
        "\n",
        "CODESTRAL_API_KEY = \"vT41MNb68fDOfyvTcXNjEfx6B9JhZyA7\"\n",
        "if not CODESTRAL_API_KEY:\n",
        "    raise ValueError(\"Missing CODESTRAL_API_KEY in environment\")\n",
        "CODESTRAL_API_BASE = os.getenv(\"CODESTRAL_API_BASE\", \"https://api.mistral.ai/v1\")\n",
        "CODESTRAL_MODEL = os.getenv(\"CODESTRAL_MODEL\", \"codestral-latest\")\n",
        "\n",
        "\n",
        "def _log(instance_id: str, message: str) -> None:\n",
        "    print(f\"[{instance_id}] {message}\")\n",
        "\n",
        "\n",
        "def run(cmd: str, cwd: Path, timeout_sec: float | None = None) -> subprocess.CompletedProcess:\n",
        "    start = time.time()\n",
        "    try:\n",
        "        proc = subprocess.run(\n",
        "            cmd,\n",
        "            cwd=str(cwd),\n",
        "            shell=True,\n",
        "            text=True,\n",
        "            capture_output=True,\n",
        "            timeout=timeout_sec,\n",
        "        )\n",
        "    except subprocess.TimeoutExpired as exc:\n",
        "        raise RuntimeError(f\"Command timed out after {timeout_sec}s: {cmd}\") from exc\n",
        "    duration = time.time() - start\n",
        "    if proc.returncode != 0:\n",
        "        raise RuntimeError(\n",
        "            f\"Command failed ({proc.returncode}) in {duration:.1f}s: {cmd}\\n\"\n",
        "            f\"STDOUT:\\n{proc.stdout}\\nSTDERR:\\n{proc.stderr}\"\n",
        "        )\n",
        "    return proc\n",
        "\n",
        "\n",
        "def get_repo_full_name(instance: Dict[str, Any]) -> str:\n",
        "    if \"repo\" in instance and instance[\"repo\"]:\n",
        "        return instance[\"repo\"]\n",
        "    if \"repo_name\" in instance and instance[\"repo_name\"]:\n",
        "        return instance[\"repo_name\"]\n",
        "    raise KeyError(\"Missing repo field in instance\")\n",
        "\n",
        "\n",
        "def build_issue_text(instance: Dict[str, Any]) -> str:\n",
        "    parts = []\n",
        "    if instance.get(\"title\"):\n",
        "        parts.append(instance[\"title\"])\n",
        "    if instance.get(\"problem_statement\"):\n",
        "        parts.append(instance[\"problem_statement\"])\n",
        "    hints = instance.get(\"hints_text\") or \"\"\n",
        "    if hints.strip():\n",
        "        parts.append(\"HINTS:\\n\" + hints)\n",
        "    return \"\\n\\n\".join(parts).strip()\n",
        "\n",
        "\n",
        "def _backoff_sleep(attempt: int) -> None:\n",
        "    base = float(globals().get(\"RETRY_BASE_DELAY_SEC\", 2.0))\n",
        "    max_delay = float(globals().get(\"RETRY_MAX_DELAY_SEC\", 60.0))\n",
        "    jitter = random.uniform(0.0, 1.0)\n",
        "    delay = min(max_delay, base * (2 ** attempt)) + jitter\n",
        "    time.sleep(delay)\n",
        "\n",
        "\n",
        "def run_agent_on_instance(instance: Dict[str, Any], work_dir: Path) -> str:\n",
        "    instance_id = str(instance.get(\"instance_id\", \"unknown\"))\n",
        "    repo_full = get_repo_full_name(instance)\n",
        "    base_commit = instance[\"base_commit\"]\n",
        "    issue_text = build_issue_text(instance)\n",
        "\n",
        "    clone_timeout = float(globals().get(\"GIT_CLONE_TIMEOUT_SEC\", 600.0))\n",
        "    checkout_timeout = float(globals().get(\"GIT_CHECKOUT_TIMEOUT_SEC\", 120.0))\n",
        "    diff_timeout = float(globals().get(\"DIFF_TIMEOUT_SEC\", 60.0))\n",
        "\n",
        "    _log(instance_id, f\"start repo={repo_full} base_commit={base_commit}\")\n",
        "    with tempfile.TemporaryDirectory(prefix=\"swebench-\", dir=work_dir) as tmp:\n",
        "        tmp_path = Path(tmp)\n",
        "        repo_dir = tmp_path / repo_full.replace(\"/\", \"__\")\n",
        "        clone_url = f\"https://github.com/{repo_full}.git\"\n",
        "\n",
        "        _log(instance_id, \"cloning repo\")\n",
        "        run(f\"git clone {clone_url} {repo_dir.name}\", cwd=tmp_path, timeout_sec=clone_timeout)\n",
        "\n",
        "        _log(instance_id, \"checking out base commit\")\n",
        "        run(f\"git checkout {base_commit}\", cwd=repo_dir, timeout_sec=checkout_timeout)\n",
        "\n",
        "        _log(instance_id, \"building context (may take a while)\")\n",
        "        t0 = time.time()\n",
        "        context = _build_context(repo_dir, issue_text)\n",
        "        _log(instance_id, f\"context built in {time.time() - t0:.1f}s\")\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": PROMPT_CODE_PATCH},\n",
        "            {\"role\": \"user\", \"content\": context},\n",
        "        ]\n",
        "\n",
        "        max_attempts = int(globals().get(\"RETRY_MAX_ATTEMPTS\", 5))\n",
        "        last_exc: Exception | None = None\n",
        "        response = None\n",
        "        for attempt in range(max_attempts):\n",
        "            try:\n",
        "                _log(instance_id, f\"LLM attempt {attempt + 1}/{max_attempts}\")\n",
        "                response = chat(\n",
        "                    CODESTRAL_API_BASE,\n",
        "                    CODESTRAL_API_KEY,\n",
        "                    CODESTRAL_MODEL,\n",
        "                    messages,\n",
        "                    temperature=0.2,\n",
        "                    max_tokens=2048,\n",
        "                    timeout_sec=120,\n",
        "                )\n",
        "                last_exc = None\n",
        "                break\n",
        "            except Exception as exc:\n",
        "                last_exc = exc\n",
        "                _log(instance_id, f\"LLM error: {exc}\")\n",
        "                if attempt < max_attempts - 1:\n",
        "                    _backoff_sleep(attempt)\n",
        "        if response is None:\n",
        "            raise last_exc or RuntimeError(\"LLM call failed\")\n",
        "\n",
        "        data = extract_json(response.content)\n",
        "        _apply_file_changes(repo_dir, data)\n",
        "        diff = run(\"git diff --no-color\", cwd=repo_dir, timeout_sec=diff_timeout)\n",
        "        _log(instance_id, f\"diff size={len(diff.stdout)} chars\")\n",
        "        return diff.stdout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1963e41d",
      "metadata": {},
      "source": [
        "## 4b) Smoke test (single instance)\n",
        "Run this to verify the agent completes one instance end-to-end.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "841ae4f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[astropy__astropy-12907] start repo=astropy/astropy base_commit=d16bfe05a744909de4b27f5875fe0d4ed41ce607\n",
            "[astropy__astropy-12907] cloning repo\n",
            "[astropy__astropy-12907] checking out base commit\n",
            "[astropy__astropy-12907] building context (may take a while)\n",
            "[astropy__astropy-12907] context built in 12.6s\n",
            "[astropy__astropy-12907] LLM attempt 1/8\n",
            "[astropy__astropy-12907] LLM error: LLM HTTP 429: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
            "[astropy__astropy-12907] LLM attempt 2/8\n",
            "[astropy__astropy-12907] LLM error: LLM HTTP 429: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
            "[astropy__astropy-12907] LLM attempt 3/8\n",
            "[astropy__astropy-12907] LLM error: LLM HTTP 429: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
            "[astropy__astropy-12907] LLM attempt 4/8\n",
            "[astropy__astropy-12907] LLM error: LLM HTTP 429: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
            "[astropy__astropy-12907] LLM attempt 5/8\n",
            "[astropy__astropy-12907] LLM error: LLM HTTP 429: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
            "[astropy__astropy-12907] LLM attempt 6/8\n",
            "[astropy__astropy-12907] LLM error: LLM HTTP 429: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
            "[astropy__astropy-12907] LLM attempt 7/8\n",
            "[astropy__astropy-12907] LLM error: LLM HTTP 429: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
            "[astropy__astropy-12907] LLM attempt 8/8\n",
            "[astropy__astropy-12907] LLM error: LLM HTTP 429: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n"
          ]
        },
        {
          "ename": "LlmError",
          "evalue": "LLM HTTP 429: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mLlmError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m instance = dataset[\u001b[32m0\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m patch = \u001b[43mrun_agent_on_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWORK_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPatch chars: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(patch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(patch[:\u001b[32m2000\u001b[39m])\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mrun_agent_on_instance\u001b[39m\u001b[34m(instance, work_dir)\u001b[39m\n\u001b[32m    128\u001b[39m             _backoff_sleep(attempt)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m last_exc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLLM call failed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    132\u001b[39m data = extract_json(response.content)\n\u001b[32m    133\u001b[39m _apply_file_changes(repo_dir, data)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 113\u001b[39m, in \u001b[36mrun_agent_on_instance\u001b[39m\u001b[34m(instance, work_dir)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    112\u001b[39m     _log(instance_id, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLLM attempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_attempts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     response = \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCODESTRAL_API_BASE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCODESTRAL_API_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCODESTRAL_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m     last_exc = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\MegaScholaITMO\\coding-agent\\src\\sdlc_agent\\llm.py:58\u001b[39m, in \u001b[36mchat\u001b[39m\u001b[34m(api_base, api_key, model, messages, temperature, max_tokens, timeout_sec, retries)\u001b[39m\n\u001b[32m     56\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     57\u001b[39m         time.sleep(\u001b[32m1\u001b[39m + attempt)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m LlmError(\u001b[38;5;28mstr\u001b[39m(last_error))\n",
            "\u001b[31mLlmError\u001b[39m: LLM HTTP 429: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}"
          ]
        }
      ],
      "source": [
        "instance = dataset[0]\n",
        "patch = run_agent_on_instance(instance, WORK_DIR)\n",
        "print(f\"Patch chars: {len(patch)}\")\n",
        "print(patch[:2000])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57b1a241",
      "metadata": {},
      "source": [
        "## 5) Generate predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ff627b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Starting instance astropy__astropy-12907\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import time\n",
        "\n",
        "rows = []\n",
        "sleep_between = float(globals().get(\"SLEEP_BETWEEN_INSTANCES_SEC\", 1.0))\n",
        "for instance in dataset:\n",
        "    instance_id = instance[\"instance_id\"]\n",
        "    print(f\"[INFO] {instance_id}: start\")\n",
        "    try:\n",
        "        patch = run_agent_on_instance(instance, WORK_DIR)\n",
        "    except Exception as exc:\n",
        "        patch = \"\"\n",
        "        print(f\"[WARN] {instance_id}: {exc}\")\n",
        "    rows.append({\n",
        "        \"instance_id\": instance_id,\n",
        "        \"model_name_or_path\": AGENT_NAME,\n",
        "        \"model_patch\": patch,\n",
        "    })\n",
        "    print(f\"[INFO] {instance_id}: done patch_chars={len(patch)}\")\n",
        "    if sleep_between > 0:\n",
        "        time.sleep(sleep_between)\n",
        "\n",
        "with PREDICTIONS_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    for row in rows:\n",
        "        f.write(json.dumps(row) + \"\\n\")\n",
        "\n",
        "PREDICTIONS_PATH\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b5b7696",
      "metadata": {},
      "source": [
        "## 6) Evaluate with the SWE-bench harness\n",
        "If your SWE-bench version uses a different worker flag, run `python -m swebench.harness.run_evaluation --help` and adjust.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "427ac138",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m swebench.harness.run_evaluation \\\n",
        "    --dataset_name {DATASET_NAME} \\\n",
        "    --predictions_path {PREDICTIONS_PATH} \\\n",
        "    --max_workers {MAX_WORKERS} \\\n",
        "    --run_id {RUN_ID}\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
